# ğŸ” Design Publications Scraper

Sistema inteligente para coleta automatizada de publicaÃ§Ãµes acadÃªmicas de Design, UX e Tecnologia de mÃºltiplas bases de dados cientÃ­ficas brasileiras.

## ğŸ—ï¸ Estrutura do Projeto

```
design-publications-scraper/
â”œâ”€â”€ ğŸ“ src/design_scraper/          # Core do sistema
â”‚   â”œâ”€â”€ ğŸ“ core/                    # LÃ³gica principal
â”‚   â”œâ”€â”€ ğŸ“ config/                  # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ ğŸ“ scrapers/                # MÃ³dulos de scraping
â”‚   â””â”€â”€ ğŸ“ utils/                   # UtilitÃ¡rios
â”œâ”€â”€ ğŸ“ cli/                         # Interface de linha de comando
â”œâ”€â”€ ğŸ“ web/                         # Interface web (Streamlit)
â”œâ”€â”€ ğŸ“ docs/                        # DocumentaÃ§Ã£o
â”œâ”€â”€ ğŸ“ data/                        # Dados processados
â”œâ”€â”€ ğŸ“ tests/                       # Testes automatizados
â””â”€â”€ ğŸ“ requirements.txt             # DependÃªncias Python
```

## ğŸš€ Como Usar

### ğŸ¤– **AutomaÃ§Ã£o (CLI)**
Para execuÃ§Ã£o automatizada e em lote:

```bash
# Pipeline completo
python cli/run.py

# Interface CLI interativa
python cli/run_cli.py

# Teste do sistema de filtros
python cli/test_filtering.py
```

**âš ï¸ Importante**: Execute sempre a partir do diretÃ³rio raiz do projeto para que os imports funcionem corretamente.

### ğŸŒ **Interface Manual (Web)**
Para busca personalizada e exploraÃ§Ã£o:

```bash
# Interface Streamlit
streamlit run web/streamlit_app.py

# Ou usando o script de entrada
python web/run_streamlit.py
```

**âš ï¸ Importante**: Execute sempre a partir do diretÃ³rio raiz do projeto para que os imports funcionem corretamente.

**ğŸ“Š Funcionalidade**: A interface web traz apenas resultados brutos dos scrapers, sem filtros ou deduplicaÃ§Ã£o.

## ğŸ“‹ Funcionalidades

### ğŸ¯ **Sistema de Filtros Inteligente (Pipeline Automatizado)**
- **DetecÃ§Ã£o de idioma**: Apenas tÃ­tulos em portuguÃªs
- **Palavras-chave**: 50+ termos relacionados a UX/Design
- **TransformaÃ§Ã£o**: Estrutura compatÃ­vel com base de dados

**âš ï¸ Nota**: Os filtros sÃ£o aplicados apenas no pipeline automatizado (CLI), nÃ£o na interface web.

### ğŸ” **DeduplicaÃ§Ã£o AutomÃ¡tica (Pipeline Automatizado)**
- **Baseado em links**: IdentificaÃ§Ã£o Ãºnica de publicaÃ§Ãµes
- **NÃ£o sobrescreve**: Novos registros salvos separadamente
- **RevisÃ£o manual**: Controle total sobre atualizaÃ§Ãµes

**âš ï¸ Nota**: A deduplicaÃ§Ã£o Ã© executada apenas no pipeline automatizado (CLI), nÃ£o na interface web.

### ğŸ“Š **RepositÃ³rios Suportados**
- Estudos em Design
- InfoDesign
- Human Factors in Design
- Arcos Design
- Design e Tecnologia
- TrÃ­ades em Revista
- EducaÃ§Ã£o GrÃ¡fica

## âš™ï¸ ConfiguraÃ§Ã£o

### **Pipeline Automatizado**
Edite `src/design_scraper/config/config.yaml`:

```yaml
repos:
  "Estudos em Design": "estudos_em_design"
  "InfoDesign": "infodesign"

terms:
  - "experiencia"
  - "usuario"
  - "interface"

max_pages: 10
```

### **Interface Manual**
ConfiguraÃ§Ãµes em `src/design_scraper/config/manual_search_config.yaml`

## ğŸ“ Arquivos de SaÃ­da

```
data/
â”œâ”€â”€ ğŸ“ raw/
â”‚   â”œâ”€â”€ base_database.csv          # Base principal
â”‚   â””â”€â”€ search_results.csv         # Resultados brutos
â””â”€â”€ ğŸ“ processed/
    â”œâ”€â”€ filtered_results.csv       # ApÃ³s filtros
    â””â”€â”€ new_records.csv           # Novos registros Ãºnicos
```

## ğŸ› ï¸ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <url-do-repositorio>
cd design-publications-scraper

# Instale as dependÃªncias
pip install -r requirements.txt

# Para exportaÃ§Ã£o Excel (opcional)
pip install openpyxl
```

## ğŸ§ª Testes

```bash
# Teste do sistema de filtros
python cli/test_filtering.py

# Teste do pipeline automatizado
python cli/run_cli.py

# Teste da interface web
streamlit run web/streamlit_app.py
```

## ğŸ“š DocumentaÃ§Ã£o

- **`docs/ESTRUTURA_PROJETO.md`**: DocumentaÃ§Ã£o completa da estrutura
- **`docs/SEPARACAO_RESPONSABILIDADES.md`**: SeparaÃ§Ã£o entre CLI e Web
- **`docs/CORRECOES_IMPORTS.md`**: CorreÃ§Ãµes tÃ©cnicas realizadas
- **`src/design_scraper/`**: CÃ³digo fonte com documentaÃ§Ã£o inline

## ğŸ”§ Desenvolvimento

### **Estrutura de MÃ³dulos**
- **`core/`**: LÃ³gica principal do sistema
- **`scrapers/`**: ImplementaÃ§Ãµes especÃ­ficas de cada repositÃ³rio
- **`utils/`**: FunÃ§Ãµes utilitÃ¡rias compartilhadas
- **`config/`**: Arquivos de configuraÃ§Ã£o

### **Extensibilidade**
- Adicione novos scrapers em `src/design_scraper/scrapers/`
- Configure novos repositÃ³rios em `config.yaml`
- Personalize filtros em `utils/data_transformer.py`

## ğŸ”§ Troubleshooting

### **Erro: "No module named 'design_scraper'"**
**Causa**: Imports nÃ£o conseguem encontrar os mÃ³dulos
**SoluÃ§Ã£o**: Execute sempre a partir do diretÃ³rio raiz do projeto

```bash
# âœ… CORRETO: Execute da raiz
cd design-publications-scraper
python cli/run.py

# âŒ INCORRETO: Execute de dentro de cli/
cd cli
python run.py  # Isso vai falhar
```

### **Erro: "ModuleNotFoundError"**
**Causa**: Python nÃ£o consegue resolver os imports relativos
**SoluÃ§Ã£o**: Todos os scripts jÃ¡ estÃ£o configurados com o caminho correto

## ğŸ“ Suporte

Para problemas ou dÃºvidas:
1. Verifique os logs de execuÃ§Ã£o
2. Execute os testes de validaÃ§Ã£o
3. Consulte a documentaÃ§Ã£o em `docs/`
4. Verifique as configuraÃ§Ãµes YAML

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a MIT. Veja o arquivo LICENSE para detalhes.

---

**ğŸ¯ Sistema completo para coleta inteligente de publicaÃ§Ãµes acadÃªmicas de Design!**