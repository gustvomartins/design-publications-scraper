# Design Publications Scraper

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Sistema profissional de scraping e catalogaÃ§Ã£o de publicaÃ§Ãµes de design e UX com filtragem inteligente para curadoria.

## ğŸ¯ VisÃ£o Geral

O **Design Publications Scraper** Ã© um sistema robusto e escalÃ¡vel para coleta, transformaÃ§Ã£o e filtragem de publicaÃ§Ãµes acadÃªmicas relacionadas a design e UX. O sistema implementa:

- **Scraping inteligente** de mÃºltiplas fontes acadÃªmicas
- **TransformaÃ§Ã£o automÃ¡tica** de dados para formato padronizado
- **Filtragem rigorosa** por relevÃ¢ncia e idioma portuguÃªs
- **Pipeline integrado** com todas as etapas automatizadas
- **Interface de linha de comando** profissional
- **Sistema de testes** abrangente

## ğŸ—ï¸ Estrutura do Projeto

```
design-publications-scraper/
â”œâ”€â”€ src/design_scraper/           # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ core/                     # Funcionalidades principais
â”‚   â”‚   â”œâ”€â”€ pipeline.py          # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ transformer.py       # TransformaÃ§Ã£o de dados
â”‚   â”‚   â””â”€â”€ filter.py            # Filtragem de conteÃºdo
â”‚   â”œâ”€â”€ scrapers/                 # Scrapers web
â”‚   â”‚   â”œâ”€â”€ base_scraper.py      # Classe base abstrata
â”‚   â”‚   â”œâ”€â”€ estudosemdesign_scraper.py
â”‚   â”‚   â”œâ”€â”€ infodesign_scraper.py
â”‚   â”‚   â””â”€â”€ ...                  # Outros scrapers
â”‚   â”œâ”€â”€ utils/                    # UtilitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ scrapers_factory.py  # Factory para scrapers
â”‚   â”‚   â”œâ”€â”€ deduplication.py     # LÃ³gica de deduplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ export_csv.py        # ExportaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ config/                   # Gerenciamento de configuraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ config_manager.py    # Gerenciador de configuraÃ§Ã£o
â”‚   â”‚   â””â”€â”€ defaults.py          # ConfiguraÃ§Ãµes padrÃ£o
â”‚   â””â”€â”€ cli/                     # Interface de linha de comando
â”‚       â””â”€â”€ main.py              # CLI principal
â”œâ”€â”€ tests/                        # Testes automatizados
â”‚   â”œâ”€â”€ unit/                     # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ integration/              # Testes de integraÃ§Ã£o
â”‚   â””â”€â”€ conftest.py              # ConfiguraÃ§Ã£o do pytest
â”œâ”€â”€ docs/                         # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ api/                      # DocumentaÃ§Ã£o da API
â”‚   â”œâ”€â”€ user_guide/               # Guia do usuÃ¡rio
â”‚   â””â”€â”€ developer_guide/          # Guia do desenvolvedor
â”œâ”€â”€ examples/                     # Exemplos de uso
â”œâ”€â”€ scripts/                      # Scripts utilitÃ¡rios
â”œâ”€â”€ configs/                      # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ data/                         # Dados e resultados
â”œâ”€â”€ pyproject.toml               # ConfiguraÃ§Ã£o do projeto
â”œâ”€â”€ requirements.txt              # DependÃªncias
â””â”€â”€ README.md                    # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### InstalaÃ§Ã£o do Projeto

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/design-publications/scraper.git
   cd design-publications-scraper
   ```

2. **Instale o projeto em modo desenvolvimento:**
   ```bash
   pip install -e .
   ```

3. **Instale as dependÃªncias de desenvolvimento (opcional):**
   ```bash
   pip install -e ".[dev]"
   ```

4. **Instale as dependÃªncias de documentaÃ§Ã£o (opcional):**
   ```bash
   pip install -e ".[docs]"
   ```

## ğŸ’» Uso

### Interface de Linha de Comando

O sistema oferece uma CLI profissional com comandos intuitivos:

#### Executar Pipeline Completo
```bash
# Executar com configuraÃ§Ã£o padrÃ£o
design-scraper run

# Executar com configuraÃ§Ã£o personalizada
design-scraper run --config configs/my_config.yaml
```

#### Transformar Dados Apenas
```bash
# Transformar resultados de busca
design-scraper transform input.csv output.csv

# Transformar com validaÃ§Ã£o de base de dados
design-scraper transform input.csv output.csv --base-db base.csv
```

#### Filtrar ConteÃºdo para Curadoria
```bash
# Filtrar dados transformados
design-scraper filter transformed.csv curation.csv
```

#### Gerenciar ConfiguraÃ§Ã£o
```bash
# Mostrar configuraÃ§Ã£o atual
design-scraper config show

# Validar arquivo de configuraÃ§Ã£o
design-scraper config validate
```

#### Obter Ajuda
```bash
# Ajuda geral
design-scraper --help

# Ajuda especÃ­fica de comando
design-scraper run --help
```

### Uso como MÃ³dulo Python

```python
from design_scraper.core import Pipeline, DataTransformer, ContentFilter

# Executar pipeline completo
pipeline = Pipeline("configs/config.yaml")
pipeline.run_all_scrapers()

# Transformar dados
transformer = DataTransformer()
transformed_data = transformer.transform_and_save_results(
    "input.csv", "output.csv"
)

# Filtrar conteÃºdo
filter_tool = ContentFilter()
curation_data = filter_tool.filter_and_save_for_curation(
    "transformed.csv", "curation.csv"
)
```

### Executar como MÃ³dulo

```bash
# Executar pipeline completo
python -m design_scraper run

# Executar comando especÃ­fico
python -m design_scraper transform input.csv output.csv
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo de ConfiguraÃ§Ã£o

O sistema usa arquivos YAML para configuraÃ§Ã£o:

```yaml
# configs/config.yaml
repos:
  estudos_em_design: estudos_em_design
  infodesign: infodesign
  human_factors_in_design: human_factors_in_design
  arcos_design: arcos_design
  design_e_tecnologia: design_e_tecnologia
  triades: triades
  educacao_grafica: educacao_grafica

terms:
  - "experiencia"
  - "usuario"
  - "interface"
  - "usabilidade"
  - "interacao"
  - "sistema"
  - "ergonomia"
  - "digital"
  - "informacao"
  - "tecnologia"

max_pages: 10
csv_filename: "data/raw/search_results.csv"

data_processing:
  transformed_results: "data/processed/transformed_results.csv"
  enable_auto_transform: true

curation:
  curation_candidates: "data/processed/curation_candidates.csv"
  enable_auto_filtering: true

deduplication:
  base_database: "data/raw/base_database.csv"
  new_records_output: "data/processed/new_records.csv"
  enable_auto_dedup: true
```

### ConfiguraÃ§Ãµes AvanÃ§adas

O sistema suporta configuraÃ§Ãµes avanÃ§adas para:

- **Scrapers**: URLs, delays, timeouts
- **Processamento**: Tamanho de lote, workers, tentativas
- **Filtragem**: PontuaÃ§Ã£o mÃ­nima, padrÃµes de exclusÃ£o
- **SaÃ­da**: Encoding, formato de data, metadados

## ğŸ§ª Testes

### Executar Testes

```bash
# Executar todos os testes
pytest

# Executar testes unitÃ¡rios
pytest tests/unit/

# Executar testes de integraÃ§Ã£o
pytest tests/integration/

# Executar com cobertura
pytest --cov=src/design_scraper

# Executar testes especÃ­ficos
pytest tests/unit/test_transformer.py::TestDataTransformer::test_transform_search_results
```

### ConfiguraÃ§Ã£o de Testes

O projeto usa:
- **pytest** como framework de testes
- **pytest-cov** para cobertura de cÃ³digo
- **unittest.mock** para mocks e stubs
- **Fixtures** para dados de teste reutilizÃ¡veis

## ğŸ“š DocumentaÃ§Ã£o

### DocumentaÃ§Ã£o da API

```bash
# Gerar documentaÃ§Ã£o da API
cd docs/api
make html
```

### Guias do UsuÃ¡rio

- **Guia de Filtragem**: `docs/user_guide/curation_filtering_guide.md`
- **Resumo do Sistema**: `docs/developer_guide/complete_system_summary.md`
- **Guia de TransformaÃ§Ã£o**: `docs/developer_guide/transformation_summary.md`

### DocumentaÃ§Ã£o do Desenvolvedor

- **Estrutura do Projeto**: Este README
- **PadrÃµes de CÃ³digo**: ConfiguraÃ§Ãµes do Black, Flake8, MyPy
- **Arquitetura**: OrganizaÃ§Ã£o dos mÃ³dulos e classes

## ğŸ”§ Desenvolvimento

### PadrÃµes de CÃ³digo

O projeto segue as melhores prÃ¡ticas de Python:

- **Black** para formataÃ§Ã£o de cÃ³digo
- **Flake8** para linting
- **MyPy** para verificaÃ§Ã£o de tipos
- **Pre-commit** para hooks de qualidade

### ConfiguraÃ§Ã£o de Desenvolvimento

```bash
# Instalar hooks de pre-commit
pre-commit install

# Formatar cÃ³digo
black src/ tests/

# Verificar tipos
mypy src/

# Executar linting
flake8 src/ tests/
```

### Estrutura de Commits

Usamos commits semÃ¢nticos:
- `feat:` novas funcionalidades
- `fix:` correÃ§Ãµes de bugs
- `docs:` documentaÃ§Ã£o
- `test:` testes
- `refactor:` refatoraÃ§Ã£o
- `style:` formataÃ§Ã£o

## ğŸ“Š Funcionalidades

### ğŸ•·ï¸ Scraping Inteligente

- **MÃºltiplas fontes**: 7 revistas acadÃªmicas brasileiras
- **Scrapers especializados**: Cada fonte tem seu scraper otimizado
- **Controle de taxa**: Delays configurÃ¡veis para evitar bloqueios
- **Tratamento de erros**: RecuperaÃ§Ã£o robusta de falhas

### ğŸ”„ TransformaÃ§Ã£o de Dados

- **Estrutura padronizada**: ConversÃ£o automÃ¡tica para formato base
- **ExtraÃ§Ã£o de anos**: Inteligente de campos date/edition
- **Mapeamento de categorias**: Baseado em termos de busca
- **ValidaÃ§Ã£o automÃ¡tica**: VerificaÃ§Ã£o de integridade dos dados

### ğŸ” Filtragem para Curadoria

- **Termos especÃ­ficos**: 50+ termos de UX/Design (configurÃ¡veis)
- **Sistema de pontuaÃ§Ã£o**: BÃ´nus para termos de alta relevÃ¢ncia
- **DetecÃ§Ã£o de idioma**: PortuguÃªs com fallback por padrÃµes
- **ExclusÃ£o automÃ¡tica**: Spam e conteÃºdo irrelevante

### ğŸ“ˆ Pipeline Integrado

- **OrquestraÃ§Ã£o automÃ¡tica**: Todas as etapas integradas
- **ConfiguraÃ§Ã£o flexÃ­vel**: YAML com validaÃ§Ã£o
- **Logs detalhados**: Monitoramento completo do processo
- **Tratamento de erros**: ContinuaÃ§Ã£o robusta em caso de falhas

## ğŸ¯ Casos de Uso

### Pesquisadores AcadÃªmicos

- Coleta sistemÃ¡tica de publicaÃ§Ãµes
- Filtragem por relevÃ¢ncia temÃ¡tica
- CatalogaÃ§Ã£o padronizada
- AnÃ¡lise de tendÃªncias

### BibliotecÃ¡rios e Curadores

- Triagem automÃ¡tica de conteÃºdo
- PriorizaÃ§Ã£o por relevÃ¢ncia
- ValidaÃ§Ã£o de idioma
- PreparaÃ§Ã£o para catalogaÃ§Ã£o

### Desenvolvedores

- Sistema modular e extensÃ­vel
- API limpa e documentada
- Testes abrangentes
- ConfiguraÃ§Ã£o flexÃ­vel

## ğŸ¤ ContribuiÃ§Ã£o

### Como Contribuir

1. **Fork** o repositÃ³rio
2. **Crie** uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. **Abra** um Pull Request

### Diretrizes de ContribuiÃ§Ã£o

- Siga os padrÃµes de cÃ³digo estabelecidos
- Adicione testes para novas funcionalidades
- Atualize a documentaÃ§Ã£o conforme necessÃ¡rio
- Use commits semÃ¢nticos
- Mantenha a compatibilidade com versÃµes anteriores

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- **Comunidade Python** por ferramentas e bibliotecas
- **AcadÃªmicos de Design** por feedback e validaÃ§Ã£o
- **Contribuidores** por melhorias e sugestÃµes

## ğŸ“ Suporte

- **Issues**: [GitHub Issues](https://github.com/design-publications/scraper/issues)
- **DocumentaÃ§Ã£o**: [DocumentaÃ§Ã£o Online](https://design-publications-scraper.readthedocs.io/)
- **Email**: team@design-publications.com

---

**Design Publications Scraper** - Transformando a coleta e catalogaÃ§Ã£o de publicaÃ§Ãµes acadÃªmicas de design e UX. ğŸ¨ğŸ“š