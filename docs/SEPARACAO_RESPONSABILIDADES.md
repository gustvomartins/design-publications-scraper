# ğŸ¯ SeparaÃ§Ã£o de Responsabilidades - Design Publications Scraper

## ğŸ“‹ **VisÃ£o Geral**

Este documento explica a separaÃ§Ã£o clara de responsabilidades entre as duas interfaces do sistema:

1. **ğŸ¤– Pipeline Automatizado (CLI)** - Processamento completo
2. **ğŸŒ Interface Web (Streamlit)** - Apenas scraping bruto

## ğŸ”„ **Fluxo de Dados**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RepositÃ³rios  â”‚â”€â”€â”€â–¶â”‚   Scrapers      â”‚â”€â”€â”€â–¶â”‚  Resultados     â”‚
â”‚   AcadÃªmicos    â”‚    â”‚   (CLI + Web)   â”‚    â”‚   Brutos        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Pipeline Automatizado â”‚
                    â”‚   (CLI Apenas)         â”‚
                    â”‚                         â”‚
                    â”‚ 1. Filtros (idioma)    â”‚
                    â”‚ 2. Palavras-chave      â”‚
                    â”‚ 3. DeduplicaÃ§Ã£o        â”‚
                    â”‚ 4. TransformaÃ§Ã£o       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Resultados Finais    â”‚
                    â”‚   (Processados)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤– **Pipeline Automatizado (CLI)**

### **Responsabilidades**
- âœ… **Scraping completo** de todos os repositÃ³rios configurados
- âœ… **AplicaÃ§Ã£o de filtros** (idioma portuguÃªs + palavras-chave)
- âœ… **DeduplicaÃ§Ã£o** contra base de dados existente
- âœ… **TransformaÃ§Ã£o** para estrutura padrÃ£o
- âœ… **Salvamento** de arquivos processados
- âœ… **RelatÃ³rios** detalhados de execuÃ§Ã£o

### **Comandos DisponÃ­veis**
```bash
# Pipeline completo
python cli/run.py

# Interface CLI interativa
python cli/run_cli.py

# Teste do sistema
python cli/test_filtering.py
```

### **Arquivos Gerados**
- `data/raw/search_results.csv` - Resultados brutos
- `data/processed/filtered_results.csv` - ApÃ³s filtros
- `data/processed/new_records.csv` - Novos registros Ãºnicos

### **Casos de Uso**
- ğŸ”„ **ProduÃ§Ã£o automatizada** (cron, agendamento)
- ğŸ“Š **Processamento em lote** de grandes volumes
- ğŸ” **AnÃ¡lise completa** com filtros e deduplicaÃ§Ã£o
- ğŸ’¾ **AtualizaÃ§Ã£o** da base de dados principal

## ğŸŒ **Interface Web (Streamlit)**

### **Responsabilidades**
- âœ… **Scraping sob demanda** de repositÃ³rios selecionados
- âœ… **Resultados brutos** sem processamento
- âœ… **VisualizaÃ§Ã£o interativa** dos dados
- âœ… **Download** em CSV e Excel
- âœ… **ExploraÃ§Ã£o rÃ¡pida** de dados

### **Comandos DisponÃ­veis**
```bash
# Interface web
streamlit run web/streamlit_app.py

# Script de entrada
python web/run_streamlit.py
```

### **Arquivos Gerados**
- **Nenhum arquivo salvo** automaticamente
- **Download manual** dos resultados
- **Dados temporÃ¡rios** durante a sessÃ£o

### **Casos de Uso**
- ğŸ” **ExploraÃ§Ã£o inicial** de literatura
- ğŸ“š **Pesquisa acadÃªmica** rÃ¡pida
- ğŸ¯ **AnÃ¡lise exploratÃ³ria** de dados
- ğŸ“Š **VerificaÃ§Ã£o** de disponibilidade de dados

## ğŸ” **DiferenÃ§as TÃ©cnicas**

### **Pipeline CLI**
```python
# Aplica filtros e deduplicaÃ§Ã£o
results = searcher.search_publications(
    selected_repos, repo_options, term, max_pages,
    apply_filters=True,  # âœ… Sempre True
    run_dedup=True       # âœ… Sempre True
)
```

### **Interface Web**
```python
# Apenas scraping bruto
results = searcher.search_publications_raw(
    selected_repos, repo_options, term, max_pages
    # âŒ Sem filtros
    # âŒ Sem deduplicaÃ§Ã£o
)
```

## ğŸ“Š **ComparaÃ§Ã£o de Resultados**

| Aspecto | Pipeline CLI | Interface Web |
|---------|--------------|---------------|
| **Filtros** | âœ… Aplicados | âŒ NÃ£o aplicados |
| **DeduplicaÃ§Ã£o** | âœ… Executada | âŒ NÃ£o executada |
| **TransformaÃ§Ã£o** | âœ… Estrutura padrÃ£o | âŒ Estrutura original |
| **Volume** | ğŸ”„ Todos os repositÃ³rios | ğŸ¯ RepositÃ³rios selecionados |
| **Velocidade** | ğŸŒ Processamento completo | âš¡ Scraping rÃ¡pido |
| **PersistÃªncia** | ğŸ’¾ Arquivos salvos | ğŸ“¤ Download manual |

## ğŸ¯ **Quando Usar Cada Interface**

### **Use Pipeline CLI quando:**
- ğŸ”„ **Automatizar** coleta de dados
- ğŸ“Š **Processar** grandes volumes
- ğŸ¯ **Aplicar filtros** especÃ­ficos
- ğŸ’¾ **Atualizar** base de dados
- ğŸ“ˆ **Gerar relatÃ³rios** completos

### **Use Interface Web quando:**
- ğŸ” **Explorar** dados rapidamente
- ğŸ“š **Pesquisar** tÃ³picos especÃ­ficos
- ğŸ¯ **Verificar** disponibilidade de dados
- ğŸ“Š **Analisar** tendÃªncias iniciais
- ğŸš€ **Prototipar** pesquisas

## ğŸ”§ **ImplementaÃ§Ã£o TÃ©cnica**

### **Classe ManualSearch**
```python
class ManualSearch:
    def search_publications_raw(self, ...):
        """Apenas scraping - sem processamento"""
        # Retorna resultados brutos
        
    def search_publications(self, ...):
        """Processamento completo - com filtros e dedup"""
        # Aplica filtros e deduplicaÃ§Ã£o
```

### **SeparaÃ§Ã£o de MÃ©todos**
- **`search_publications_raw()`** - Interface web
- **`search_publications()`** - Pipeline CLI
- **MÃ©todos compartilhados** - Export, configuraÃ§Ã£o

## ğŸ“ˆ **BenefÃ­cios da SeparaÃ§Ã£o**

### **âœ… Performance**
- **Interface web**: Resposta rÃ¡pida para exploraÃ§Ã£o
- **Pipeline CLI**: Processamento otimizado para volumes

### **âœ… Manutenibilidade**
- **CÃ³digo separado** para cada responsabilidade
- **Testes independentes** de cada funcionalidade
- **Debugging focado** em problemas especÃ­ficos

### **âœ… Usabilidade**
- **Interface web**: Simples e rÃ¡pida para usuÃ¡rios finais
- **Pipeline CLI**: Robusto e completo para automaÃ§Ã£o

### **âœ… Escalabilidade**
- **Interface web**: Pode ser executada em paralelo
- **Pipeline CLI**: Pode ser agendado e monitorado

## ğŸ”® **Futuras Melhorias**

### **Interface Web**
- ğŸ“Š **Filtros bÃ¡sicos** (opcional)
- ğŸ” **Busca avanÃ§ada** por campos
- ğŸ“ˆ **GrÃ¡ficos interativos** dos resultados

### **Pipeline CLI**
- ğŸ¤– **Machine Learning** para filtros inteligentes
- ğŸ“Š **MÃ©tricas avanÃ§adas** de qualidade
- ğŸ”„ **SincronizaÃ§Ã£o** com bases externas

## ğŸ“ **Suporte e Troubleshooting**

### **Problemas com Interface Web**
1. Verifique se estÃ¡ executando da raiz do projeto
2. Confirme se Streamlit estÃ¡ instalado
3. Execute `python cli/test_filtering.py` para validar scrapers

### **Problemas com Pipeline CLI**
1. Verifique configuraÃ§Ã£o em `config.yaml`
2. Confirme se diretÃ³rio `data/` existe
3. Execute `python cli/run_cli.py` para status detalhado

---

**ğŸ¯ SeparaÃ§Ã£o clara de responsabilidades para mÃ¡xima eficiÃªncia e usabilidade!**

**ğŸ“… Data**: 24/08/2025
**ğŸ”§ Status**: âœ… Implementado com sucesso
**ğŸ“Š Resultado**: Sistema mais organizado e eficiente
