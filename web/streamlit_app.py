#!/usr/bin/env python3
"""
Interface Streamlit standalone para o Design Publications Scraper.
Este arquivo pode ser executado diretamente com: streamlit run streamlit_app.py
"""

import streamlit as st
import pandas as pd
import io
import sys
import os
import tempfile

# Add the src directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

# Import required modules
try:
    from design_scraper.core.manual_search import ManualSearch
    from design_scraper.utils.scrapers_factory import ScrapterFactory
    from design_scraper.utils.data_transformer import transform_search_results
    from design_scraper.utils.deduplication import run_deduplication
except ImportError as e:
    st.error(f"‚ùå Erro ao importar m√≥dulos: {e}")
    st.info("üí° Certifique-se de que todos os m√≥dulos est√£o instalados corretamente.")
    st.stop()

def streamlit_app():
    st.set_page_config(
        page_title="Design Publications Scraper",
        page_icon="üîç",
        layout="wide"
    )
    
    st.title("üîç Scraper de Peri√≥dicos de Design")
    st.markdown("---")
    
    # Informa√ß√£o sobre a separa√ß√£o de responsabilidades
    st.info("""
    **‚ÑπÔ∏è Interface Web - Apenas Scraping**
    
    Esta interface traz resultados brutos dos scrapers, sem filtros ou deduplica√ß√£o.
    Para processamento completo (filtros + deduplica√ß√£o), use o pipeline automatizado via CLI.
    """)
    
    # Initialize manual search
    searcher = ManualSearch()
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # Repository selection (multiple choice)
        repo_options = {
            "Estudos em Design": "estudos_em_design",
            "InfoDesign": "infodesign", 
            "Human Factors in Design": "human_factors_in_design",
            "Arcos Design": "arcos_design",
            "Design e Tecnologia": "design_e_tecnologia",
            "Tr√≠ades em Revista": "triades",
            "Educa√ß√£o Gr√°fica": "educacao_grafica"
        }
        
        st.subheader("üìö Selecionar Reposit√≥rios")
        selected_repos = st.multiselect(
            "Escolha uma ou mais bases de dados:",
            options=list(repo_options.keys()),
            default=["Estudos em Design"]
        )
        
        # Search configuration
        st.subheader("üîç Configura√ß√£o da Busca")
        term = st.text_input(
            "Termos de pesquisa (m√°ximo 10 palavras):",
            placeholder="Ex: experi√™ncia do usu√°rio, usabilidade, interface"
        )
        
        max_pages = st.slider(
            "N√∫mero de p√°ginas por busca:",
            min_value=1, max_value=50, value=10
        )
        
        # Execute button
        if st.button("üöÄ Executar Busca", type="primary", use_container_width=True):
            if not selected_repos:
                st.error("‚ùå Selecione pelo menos um reposit√≥rio!")
                return
            if not term.strip():
                st.error("‚ùå O termo de pesquisa n√£o pode estar vazio!")
                return
            
            execute_manual_search(searcher, selected_repos, repo_options, term, max_pages)

def execute_manual_search(searcher, selected_repos, repo_options, term, max_pages):
    """Executa a busca manual com base nas configura√ß√µes selecionadas"""
    
    # Progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Step 1: Execute search (apenas scraping, sem filtros ou deduplica√ß√£o)
        status_text.text("üîç Executando busca...")
        progress_bar.progress(0.3)
        
        results = searcher.search_publications_raw(
            selected_repos, repo_options, term, max_pages
        )
        
        progress_bar.progress(0.8)
        
        if not results['success']:
            st.error(f"‚ùå {results['message']}")
            if 'total_scraped' in results and results['total_scraped'] > 0:
                st.info(f"üìä Total de resultados scraped: {results['total_scraped']}")
            return
        
        # Step 2: Display results
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Busca conclu√≠da!")
        
        display_results(searcher, results)
        
    except Exception as e:
        st.error(f"‚ùå Erro durante a busca: {str(e)}")
        progress_bar.progress(0)
        status_text.text("‚ùå Erro na busca")

def display_results(searcher, results):
    """Exibe os resultados e op√ß√µes de download"""
    
    st.markdown("---")
    st.header("üìä Resultados da Busca")
    
    # Get search summary
    summary = searcher.get_search_summary(results)
    
    # Summary statistics
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Total Scraped", summary['total_scraped'])
    
    with col2:
        st.metric("Resultados Finais", summary['final_results'])
    
    # Repository statistics
    if summary['scraping_stats']:
        st.subheader("üìö Estat√≠sticas por Reposit√≥rio")
        stats_df = pd.DataFrame([
            {'Reposit√≥rio': repo, 'Resultados': count} 
            for repo, count in summary['scraping_stats'].items()
            if isinstance(count, int)
        ])
        if not stats_df.empty:
            st.bar_chart(stats_df.set_index('Reposit√≥rio'))
    
    # Results table
    st.subheader("üìã Lista de Resultados")
    
    results_df = results['results_df']
    
    # Format display columns
    display_df = results_df.copy()
    if 'timestamp' in display_df.columns:
        display_df['timestamp'] = pd.to_datetime(display_df['timestamp']).dt.strftime('%Y-%m-%d %H:%M')
    
    # Show results with pagination
    max_display = 100
    if len(display_df) > max_display:
        st.info(f"Mostrando primeiros {max_display} resultados de {len(display_df)}. Use o download para ver todos.")
        display_df = display_df.head(max_display)
    
    st.dataframe(display_df, use_container_width=True)
    
    # Download options
    st.subheader("üíæ Download dos Resultados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # CSV download
        try:
            csv_data, csv_filename, csv_mime = searcher.export_results(
                results_df, "csv", "design_publications"
            )
            st.download_button(
                label="üì• Download CSV",
                data=csv_data,
                file_name=csv_filename,
                mime=csv_mime
            )
        except Exception as e:
            st.error(f"‚ùå Erro ao gerar CSV: {e}")
    
    with col2:
        # Excel download
        try:
            excel_data, excel_filename, excel_mime = searcher.export_results(
                results_df, "excel", "design_publications"
            )
            st.download_button(
                label="üì• Download Excel",
                data=excel_data,
                file_name=excel_filename,
                mime=excel_mime
            )
        except ImportError:
            st.info("üìä Excel n√£o dispon√≠vel (instale openpyxl)")
        except Exception as e:
            st.error(f"‚ùå Erro ao gerar Excel: {e}")
    
    # Return results for programmatic access
    return results_df

if __name__ == "__main__":
    streamlit_app()
